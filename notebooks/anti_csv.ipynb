{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Anti-CSV\n",
    "\n",
    "In this Jupyter notebook all CSV files from the data directory are converted to a more efficient format (such as .parquet, or if this isn't enough .feather). This should allow for faster loading of data later down the line.\n",
    "Additionally, a first data clean-up takes place: by inferring missing values with default values and rescaling some values to be closer to 1, data loss is tried to be minimized."
   ],
   "id": "6def04a8cc27c158"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import all necessary packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.ma.extras import column_stack\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ],
   "id": "c7a2448f37f7af19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fix global constants\n",
    "data_dir = Path('../data/')"
   ],
   "id": "b5c3e15a11da6de3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# some helper functions down the line\n",
    "conversion_factor = np.pi / 180.0\n",
    "def convert_to_rad(_df, _key):\n",
    "    _df[_key] = _df[_key] * conversion_factor\n",
    "    return _df\n",
    "\n",
    "def scale_km(_df, _key):\n",
    "    _df[_key] = _df[_key] / 1_000.0\n",
    "    return _df"
   ],
   "id": "408cae2a35953b98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## GOES data\n",
    "\n",
    "First of all, the GOES data is copied from `./data/raw/GOES/*.csv` to `./data/preprocessed/GOES/*.parquet`."
   ],
   "id": "f43b32cd497dcf3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "goes_raw_data_dir = Path(data_dir / 'raw/GOES/')\n",
    "goes_out_dir = Path(data_dir / 'preprocessed/GOES/')\n",
    "goes_aggregated_file = Path(data_dir / 'preprocessed/aggregated/goes.feather')"
   ],
   "id": "cd6fa07c472bab89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### First tests\n",
    "\n",
    "Before creating the more compact data sets used during training, a first analysis takes place. This allows for the choosing the correct data types for all columns. In this instance the precision from `float64` is probably not needed, hence all data is converted down to `float32`. This massively reduces the necessary memory for this data."
   ],
   "id": "4badf75164e81e8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print details about exemplary goes csv file\n",
    "folder = next(iter(os.listdir(goes_raw_data_dir)))\n",
    "file = next(iter(os.listdir(goes_raw_data_dir / folder)))\n",
    "# file = os.listdir(goes_raw_data_dir)[8000]\n",
    "df = pd.read_csv(\n",
    "    goes_raw_data_dir / folder / file,\n",
    "    sep=',',\n",
    "    index_col='Timestamp',\n",
    "    parse_dates=True,\n",
    ")\n",
    "print(df.info())\n",
    "df.describe()"
   ],
   "id": "1abd00d9bf67ca3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# reduce scale for better numerical stability\n",
    "convert_to_rad(df, 'roll_angle')\n",
    "\n",
    "# fill nan values\n",
    "for key, value in {\n",
    "    'quad_diode': -1.0,\n",
    "    'xrsa_flux': -1.0, 'xrsb_flux': -1.0,\n",
    "    'xrsa_flux_observed': -1.0, 'xrsa_flux_electrons': -1.0, 'xrsb_flux_observed': -1.0, 'xrsb_flux_electrons': -1.0,\n",
    "    'xrsa_flag': 65535, 'xrsb_flag': 65535,\n",
    "    'xrsa_num': -1.0, 'xrsb_num': -1.0, 'xrsa_flag_excluded': 65535, 'xrsb_flag_excluded': 65535,\n",
    "    'au_factor': -1.0, 'corrected_current_xrsb2': -1.0, 'roll_angle': -4.0,\n",
    "    'xrsa1_flux': -1.0, 'xrsa1_flux_observed': -1.0, 'xrsa1_flux_electrons': -1.0,\n",
    "    'xrsa2_flux': -1.0, 'xrsa2_flux_observed': -1.0, 'xrsa2_flux_electrons': -1.0,\n",
    "    'xrsb1_flux': -1.0, 'xrsb1_flux_observed': -1.0, 'xrsb1_flux_electrons': -1.0,\n",
    "    'xrsb2_flux': -1.0, 'xrsb2_flux_observed': -1.0, 'xrsb2_flux_electrons': -1.0,\n",
    "    'xrs_primary_chan': 65535, 'xrsa1_flag': 255, 'xrsa2_flag': 255, 'xrsb1_flag': 255, 'xrsb2_flag': 255,\n",
    "    'xrsa1_num': -1, 'xrsa2_num': -1, 'xrsb1_num': -1, 'xrsb2_num': -1,\n",
    "    'xrsa1_flag_excluded': 65535, 'xrsa2_flag_excluded': 65535, 'xrsb1_flag_excluded': 65535, 'xrsb2_flag_excluded': 65535,\n",
    "    'yaw_flip_flag': 255\n",
    "}.items():\n",
    "    df[key] = df[key].fillna(value)\n",
    "\n",
    "# Convert to correct formats\n",
    "df = df.astype({\n",
    "    'quad_diode': np.float32,\n",
    "    'xrsa_flux': np.float32,\n",
    "    'xrsa_flux_observed': np.float32,\n",
    "    'xrsa_flux_electrons': np.float32,\n",
    "    'xrsb_flux': np.float32,\n",
    "    'xrsb_flux_observed': np.float32,\n",
    "    'xrsb_flux_electrons': np.float32,\n",
    "    'xrsa_flag': np.uint16,\n",
    "    'xrsb_flag': np.uint16,\n",
    "    'xrsa_num': np.int32,\n",
    "    'xrsb_num': np.int32,\n",
    "    'xrsa_flag_excluded': np.uint16,\n",
    "    'xrsb_flag_excluded': np.uint16,\n",
    "    'au_factor': np.float32,\n",
    "    'corrected_current_xrsb2': np.float32,\n",
    "    'roll_angle': np.float32,\n",
    "    'xrsa1_flux': np.float32,\n",
    "    'xrsa1_flux_observed': np.float32,\n",
    "    'xrsa1_flux_electrons': np.float32,\n",
    "    'xrsa2_flux': np.float32,\n",
    "    'xrsa2_flux_observed': np.float32,\n",
    "    'xrsa2_flux_electrons': np.float32,\n",
    "    'xrsb1_flux': np.float32,\n",
    "    'xrsb1_flux_observed': np.float32,\n",
    "    'xrsb1_flux_electrons': np.float32,\n",
    "    'xrsb2_flux': np.float32,\n",
    "    'xrsb2_flux_observed': np.float32,\n",
    "    'xrsb2_flux_electrons': np.float32,\n",
    "    'xrs_primary_chan': np.uint16,\n",
    "    'xrsa1_flag': np.uint8,\n",
    "    'xrsa2_flag': np.uint8,\n",
    "    'xrsb1_flag': np.uint8,\n",
    "    'xrsb2_flag': np.uint8,\n",
    "    'xrsa1_num': np.int32,\n",
    "    'xrsa2_num': np.int32,\n",
    "    'xrsb1_num': np.int32,\n",
    "    'xrsb2_num': np.int32,\n",
    "    'xrsa1_flag_excluded': np.uint16,\n",
    "    'xrsa2_flag_excluded': np.uint16,\n",
    "    'xrsb1_flag_excluded': np.uint16,\n",
    "    'xrsb2_flag_excluded': np.uint16,\n",
    "    'yaw_flip_flag': np.uint8,\n",
    "})\n",
    "print(df.info())"
   ],
   "id": "51c7bdefb00941d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conversion\n",
    "\n",
    "After finding out, how the data must be transformed, the transformations can be applied to all csv files."
   ],
   "id": "42e5af93073cb1c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for all single files\n",
    "for csv_file in tqdm(os.listdir(goes_raw_data_dir)):\n",
    "    df = pd.read_csv(\n",
    "        goes_raw_data_dir / csv_file,\n",
    "        sep=',',\n",
    "        index_col='Timestamp',\n",
    "        parse_dates=True,\n",
    "    )\n",
    "    # reduce scale for better numerical stability\n",
    "    convert_to_rad(df, 'roll_angle')\n",
    "\n",
    "    # fill nan values\n",
    "    for key, value in {\n",
    "        'quad_diode': -1.0,\n",
    "        'xrsa_flux': -1.0, 'xrsb_flux': -1.0,\n",
    "        'xrsa_flux_observed': -1.0, 'xrsa_flux_electrons': -1.0, 'xrsb_flux_observed': -1.0, 'xrsb_flux_electrons': -1.0,\n",
    "        'xrsa_flag': 65535, 'xrsb_flag': 65535,\n",
    "        'xrsa_num': -1.0, 'xrsb_num': -1.0, 'xrsa_flag_excluded': 65535, 'xrsb_flag_excluded': 65535,\n",
    "        'au_factor': -1.0, 'corrected_current_xrsb2': -1.0, 'roll_angle': -4.0,\n",
    "        'xrsa1_flux': -1.0, 'xrsa1_flux_observed': -1.0, 'xrsa1_flux_electrons': -1.0,\n",
    "        'xrsa2_flux': -1.0, 'xrsa2_flux_observed': -1.0, 'xrsa2_flux_electrons': -1.0,\n",
    "        'xrsb1_flux': -1.0, 'xrsb1_flux_observed': -1.0, 'xrsb1_flux_electrons': -1.0,\n",
    "        'xrsb2_flux': -1.0, 'xrsb2_flux_observed': -1.0, 'xrsb2_flux_electrons': -1.0,\n",
    "        'xrs_primary_chan': 65535, 'xrsa1_flag': 255, 'xrsa2_flag': 255, 'xrsb1_flag': 255, 'xrsb2_flag': 255,\n",
    "        'xrsa1_num': -1, 'xrsa2_num': -1, 'xrsb1_num': -1, 'xrsb2_num': -1,\n",
    "        'xrsa1_flag_excluded': 65535, 'xrsa2_flag_excluded': 65535, 'xrsb1_flag_excluded': 65535, 'xrsb2_flag_excluded': 65535,\n",
    "        'yaw_flip_flag': 255\n",
    "    }.items():\n",
    "        df[key] = df[key].fillna(value)\n",
    "\n",
    "    # Convert to correct formats\n",
    "    df = df.astype({\n",
    "        'quad_diode': np.float32,\n",
    "        'xrsa_flux': np.float32,\n",
    "        'xrsa_flux_observed': np.float32,\n",
    "        'xrsa_flux_electrons': np.float32,\n",
    "        'xrsb_flux': np.float32,\n",
    "        'xrsb_flux_observed': np.float32,\n",
    "        'xrsb_flux_electrons': np.float32,\n",
    "        'xrsa_flag': np.uint16,\n",
    "        'xrsb_flag': np.uint16,\n",
    "        'xrsa_num': np.int32,\n",
    "        'xrsb_num': np.int32,\n",
    "        'xrsa_flag_excluded': np.uint16,\n",
    "        'xrsb_flag_excluded': np.uint16,\n",
    "        'au_factor': np.float32,\n",
    "        'corrected_current_xrsb2': np.float32,\n",
    "        'roll_angle': np.float32,\n",
    "        'xrsa1_flux': np.float32,\n",
    "        'xrsa1_flux_observed': np.float32,\n",
    "        'xrsa1_flux_electrons': np.float32,\n",
    "        'xrsa2_flux': np.float32,\n",
    "        'xrsa2_flux_observed': np.float32,\n",
    "        'xrsa2_flux_electrons': np.float32,\n",
    "        'xrsb1_flux': np.float32,\n",
    "        'xrsb1_flux_observed': np.float32,\n",
    "        'xrsb1_flux_electrons': np.float32,\n",
    "        'xrsb2_flux': np.float32,\n",
    "        'xrsb2_flux_observed': np.float32,\n",
    "        'xrsb2_flux_electrons': np.float32,\n",
    "        'xrs_primary_chan': np.uint16,\n",
    "        'xrsa1_flag': np.uint8,\n",
    "        'xrsa2_flag': np.uint8,\n",
    "        'xrsb1_flag': np.uint8,\n",
    "        'xrsb2_flag': np.uint8,\n",
    "        'xrsa1_num': np.int32,\n",
    "        'xrsa2_num': np.int32,\n",
    "        'xrsb1_num': np.int32,\n",
    "        'xrsb2_num': np.int32,\n",
    "        'xrsa1_flag_excluded': np.uint16,\n",
    "        'xrsa2_flag_excluded': np.uint16,\n",
    "        'xrsb1_flag_excluded': np.uint16,\n",
    "        'xrsb2_flag_excluded': np.uint16,\n",
    "        'yaw_flip_flag': np.uint8,\n",
    "    })\n",
    "\n",
    "    df.to_parquet(goes_out_dir / f'{Path(csv_file).stem}.parquet')"
   ],
   "id": "4a05087988833457",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## OMNI data\n",
    "\n",
    "First of all, the OMNI data is copied from `./data/raw/OMNI2/*.csv` to `./data/preprocessed/OMNI2/*.parquet`."
   ],
   "id": "e0f50ea7cb0dee7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "omni_raw_data_dir = Path(data_dir / 'raw/OMNI2/')\n",
    "omni_out_dir = Path(data_dir / 'preprocessed/OMNI2/')\n",
    "# omni_aggregated_file = Path(data_dir / 'preprocessed/aggregated/omni2.feather')"
   ],
   "id": "656f946f18eeb9c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# helper functions\n",
    "def _convert_nt_to_ut(_df, _key):\n",
    "    _df[_key] = _df[_key] * 1e-3\n",
    "    _df.rename(columns={_key: _key.replace('_nT', '_uT')}, inplace=True)\n",
    "\n",
    "def _convert_T_to_10_5_T(_df, _key):\n",
    "    _df[_key] = _df[_key] / 1e5\n",
    "    _df.rename(columns={_key: _key.replace('_K', '_10_5K')}, inplace=True)\n",
    "\n",
    "def _convert_km_s_to_km_ms(_df, _key):\n",
    "    _df[_key] = _df[_key] / 1e3\n",
    "    _df.rename(columns={_key: _key.replace('_km_s', '_km_ms')}, inplace=True)"
   ],
   "id": "ae83f317765261f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### First tests\n",
    "\n",
    "Before creating the more compact data sets used during training, a first analysis takes place. This allows for the choosing the correct data types for all columns. In this instance the precision from `float64` is probably not needed, hence all data is converted down to `float32`. This massively reduces the necessary memory for this data.\n",
    "(see [this](https://i.sstatic.net/V7kvk.png) for more details of how the correct data type has been chosen)"
   ],
   "id": "84f63de6b7f416db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print details about exemplary goes csv file\n",
    "file = next(iter(os.listdir(omni_raw_data_dir)))\n",
    "df = pd.read_csv(\n",
    "    omni_raw_data_dir / file,\n",
    "    sep=',',\n",
    "    index_col='Timestamp',\n",
    "    parse_dates=True,\n",
    ")\n",
    "print(df.info())\n",
    "df.describe()"
   ],
   "id": "775ae89482754e87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for key in [\n",
    "    'Scalar_B_nT', 'Vector_B_Magnitude_nT',\n",
    "    'BX_nT_GSE_GSM', 'BY_nT_GSE', 'BZ_nT_GSE', 'BY_nT_GSM', 'BZ_nT_GSM',\n",
    "    'RMS_magnitude_nT', 'RMS_field_vector_nT', 'RMS_BX_GSE_nT', 'RMS_BY_GSE_nT', 'RMS_BZ_GSE_nT',\n",
    "    'Dst_index_nT', 'ap_index_nT',\n",
    "    'AE_index_nT', 'AL_index_nT', 'AU_index_nT'\n",
    "]:\n",
    "    _convert_nt_to_ut(df, key)\n",
    "\n",
    "for key in ['Lat_Angle_of_B_GSE', 'Long_Angle_of_B_GSE', 'SW_Plasma_flow_long_angle', 'SW_Plasma_flow_lat_angle', 'sigma_phi_V_degrees', 'sigma_theta_V_degrees']:\n",
    "    convert_to_rad(df, key)\n",
    "    df.loc[df[key] > 7, key] = -4.0     # these are outliers\n",
    "\n",
    "for key in ['SW_Plasma_Temperature_K', 'sigma_T_K']:\n",
    "    _convert_T_to_10_5_T(df, key)\n",
    "\n",
    "for key in ['SW_Plasma_Speed_km_s', 'sigma_V_km_s']:\n",
    "    _convert_km_s_to_km_ms(df, key)\n",
    "\n",
    "df.loc[df['Alpha_Prot_ratio'] > 1.0, 'Alpha_Prot_ratio'] = -1.0\n",
    "df.loc[df['sigma_ratio'] > 1.0, 'sigma_ratio'] = -1.0\n",
    "\n",
    "for i in [1, 2, 4, 10, 30, 60]:\n",
    "    key = f'Proton_flux_>{i}_Mev'\n",
    "    df[key] = df[key] / 1e3\n",
    "    df.loc[df[key] > 9e2, key] = -1.0\n",
    "    df.rename(columns={key: f'Proton_flux_>{i}_Mev_10^-3'}, inplace=True)\n",
    "\n",
    "df = df.astype({\n",
    "    'YEAR': np.uint16,\n",
    "    'DOY': np.uint16,\n",
    "    'Hour': np.uint8,\n",
    "    'Bartels_rotation_number': np.uint16,\n",
    "    'ID_for_IMF_spacecraft': np.uint16,\n",
    "    'ID_for_SW_Plasma_spacecraft': np.uint16,\n",
    "    'num_points_IMF_averages': np.int16,\n",
    "    'num_points_Plasma_averages': np.int16,\n",
    "    'Scalar_B_uT': np.float32,\n",
    "    'Vector_B_Magnitude_uT':np.float32,\n",
    "    'Lat_Angle_of_B_GSE': np.float32,\n",
    "    'Long_Angle_of_B_GSE': np.float32,\n",
    "    'BX_uT_GSE_GSM': np.float32,\n",
    "    'BY_uT_GSE': np.float32,\n",
    "    'BZ_uT_GSE': np.float32,\n",
    "    'BY_uT_GSM': np.float32,\n",
    "    'BZ_uT_GSM': np.float32,\n",
    "    'RMS_magnitude_uT': np.float32,\n",
    "    'RMS_field_vector_uT': np.float32,\n",
    "    'RMS_BX_GSE_uT': np.float32,\n",
    "    'RMS_BY_GSE_uT': np.float32,\n",
    "    'RMS_BZ_GSE_uT': np.float32,\n",
    "    'SW_Plasma_Temperature_10_5K': np.float32,\n",
    "    'SW_Proton_Density_N_cm3': np.float32,\n",
    "    'SW_Plasma_Speed_km_ms': np.float32,\n",
    "    'SW_Plasma_flow_long_angle': np.float32,\n",
    "    'SW_Plasma_flow_lat_angle': np.float32,\n",
    "    'Alpha_Prot_ratio': np.float32,\n",
    "    'sigma_T_10_5K': np.float32,\n",
    "    'sigma_n_N_cm3': np.float32,\n",
    "    'sigma_V_km_ms': np.float32,\n",
    "    'sigma_phi_V_degrees': np.float32,\n",
    "    'sigma_theta_V_degrees': np.float32,\n",
    "    'sigma_ratio': np.float32,\n",
    "    'Flow_pressure': np.float32,\n",
    "    'E_electric_field': np.float32,\n",
    "    'Plasma_Beta': np.float32,\n",
    "    'Alfen_mach_number': np.float32,\n",
    "    'Magnetosonic_Mach_number': np.float32,\n",
    "    'Quasy_Invariant': np.float32,\n",
    "    'Kp_index': np.float32,\n",
    "    'R_Sunspot_No': np.float32,\n",
    "    'Dst_index_uT': np.float32,\n",
    "    'ap_index_uT': np.float32,\n",
    "    'f10.7_index': np.float32,\n",
    "    'AE_index_uT': np.float32,\n",
    "    'AL_index_uT': np.float32,\n",
    "    'AU_index_uT': np.float32,\n",
    "    'pc_index': np.float32,\n",
    "    'Lyman_alpha': np.float32,\n",
    "    'Proton_flux_>1_Mev_10^-3': np.float32,\n",
    "    'Proton_flux_>2_Mev_10^-3': np.float32,\n",
    "    'Proton_flux_>4_Mev_10^-3': np.float32,\n",
    "    'Proton_flux_>10_Mev_10^-3': np.float32,\n",
    "    'Proton_flux_>30_Mev_10^-3': np.float32,\n",
    "    'Proton_flux_>60_Mev_10^-3': np.float32,\n",
    "    'Flux_FLAG': np.int8\n",
    "})\n",
    "print(df.info())\n",
    "df.describe()"
   ],
   "id": "18161d2876d95f74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for csv_file in tqdm(os.listdir(omni_raw_data_dir)):\n",
    "    df = pd.read_csv(\n",
    "        omni_raw_data_dir / file,\n",
    "        sep=',',\n",
    "        index_col='Timestamp',\n",
    "        parse_dates=True,\n",
    "    )\n",
    "\n",
    "    for key in [\n",
    "        'Scalar_B_nT', 'Vector_B_Magnitude_nT',\n",
    "        'BX_nT_GSE_GSM', 'BY_nT_GSE', 'BZ_nT_GSE', 'BY_nT_GSM', 'BZ_nT_GSM',\n",
    "        'RMS_magnitude_nT', 'RMS_field_vector_nT', 'RMS_BX_GSE_nT', 'RMS_BY_GSE_nT', 'RMS_BZ_GSE_nT',\n",
    "        'Dst_index_nT', 'ap_index_nT',\n",
    "        'AE_index_nT', 'AL_index_nT', 'AU_index_nT'\n",
    "    ]:\n",
    "        _convert_nt_to_ut(df, key)\n",
    "\n",
    "    for key in ['Lat_Angle_of_B_GSE', 'Long_Angle_of_B_GSE', 'SW_Plasma_flow_long_angle', 'SW_Plasma_flow_lat_angle', 'sigma_phi_V_degrees', 'sigma_theta_V_degrees']:\n",
    "        convert_to_rad(df, key)\n",
    "        df.loc[df[key] > 7, key] = -4.0     # these are outliers\n",
    "\n",
    "    for key in ['SW_Plasma_Temperature_K', 'sigma_T_K']:\n",
    "        _convert_T_to_10_5_T(df, key)\n",
    "\n",
    "    for key in ['SW_Plasma_Speed_km_s', 'sigma_V_km_s']:\n",
    "        _convert_km_s_to_km_ms(df, key)\n",
    "\n",
    "    df.loc[df['Alpha_Prot_ratio'] > 1.0, 'Alpha_Prot_ratio'] = -1.0\n",
    "    df.loc[df['sigma_ratio'] > 1.0, 'sigma_ratio'] = -1.0\n",
    "\n",
    "    for i in [1, 2, 4, 10, 30, 60]:\n",
    "        key = f'Proton_flux_>{i}_Mev'\n",
    "        df[key] = df[key] / 1e3\n",
    "        df.loc[df[key] > 9e2, key] = -1.0\n",
    "        df.rename(columns={key: f'Proton_flux_>{i}_Mev_10^-3'}, inplace=True)\n",
    "\n",
    "    df = df.astype({\n",
    "        'YEAR': np.uint16,\n",
    "        'DOY': np.uint16,\n",
    "        'Hour': np.uint8,\n",
    "        'Bartels_rotation_number': np.uint16,\n",
    "        'ID_for_IMF_spacecraft': np.uint16,\n",
    "        'ID_for_SW_Plasma_spacecraft': np.uint16,\n",
    "        'num_points_IMF_averages': np.int16,\n",
    "        'num_points_Plasma_averages': np.int16,\n",
    "        'Scalar_B_uT': np.float32,\n",
    "        'Vector_B_Magnitude_uT':np.float32,\n",
    "        'Lat_Angle_of_B_GSE': np.float32,\n",
    "        'Long_Angle_of_B_GSE': np.float32,\n",
    "        'BX_uT_GSE_GSM': np.float32,\n",
    "        'BY_uT_GSE': np.float32,\n",
    "        'BZ_uT_GSE': np.float32,\n",
    "        'BY_uT_GSM': np.float32,\n",
    "        'BZ_uT_GSM': np.float32,\n",
    "        'RMS_magnitude_uT': np.float32,\n",
    "        'RMS_field_vector_uT': np.float32,\n",
    "        'RMS_BX_GSE_uT': np.float32,\n",
    "        'RMS_BY_GSE_uT': np.float32,\n",
    "        'RMS_BZ_GSE_uT': np.float32,\n",
    "        'SW_Plasma_Temperature_10_5K': np.float32,\n",
    "        'SW_Proton_Density_N_cm3': np.float32,\n",
    "        'SW_Plasma_Speed_km_ms': np.float32,\n",
    "        'SW_Plasma_flow_long_angle': np.float32,\n",
    "        'SW_Plasma_flow_lat_angle': np.float32,\n",
    "        'Alpha_Prot_ratio': np.float32,\n",
    "        'sigma_T_10_5K': np.float32,\n",
    "        'sigma_n_N_cm3': np.float32,\n",
    "        'sigma_V_km_ms': np.float32,\n",
    "        'sigma_phi_V_degrees': np.float32,\n",
    "        'sigma_theta_V_degrees': np.float32,\n",
    "        'sigma_ratio': np.float32,\n",
    "        'Flow_pressure': np.float32,\n",
    "        'E_electric_field': np.float32,\n",
    "        'Plasma_Beta': np.float32,\n",
    "        'Alfen_mach_number': np.float32,\n",
    "        'Magnetosonic_Mach_number': np.float32,\n",
    "        'Quasy_Invariant': np.float32,\n",
    "        'Kp_index': np.float32,\n",
    "        'R_Sunspot_No': np.float32,\n",
    "        'Dst_index_uT': np.float32,\n",
    "        'ap_index_uT': np.float32,\n",
    "        'f10.7_index': np.float32,\n",
    "        'AE_index_uT': np.float32,\n",
    "        'AL_index_uT': np.float32,\n",
    "        'AU_index_uT': np.float32,\n",
    "        'pc_index': np.float32,\n",
    "        'Lyman_alpha': np.float32,\n",
    "        'Proton_flux_>1_Mev_10^-3': np.float32,\n",
    "        'Proton_flux_>2_Mev_10^-3': np.float32,\n",
    "        'Proton_flux_>4_Mev_10^-3': np.float32,\n",
    "        'Proton_flux_>10_Mev_10^-3': np.float32,\n",
    "        'Proton_flux_>30_Mev_10^-3': np.float32,\n",
    "        'Proton_flux_>60_Mev_10^-3': np.float32,\n",
    "        'Flux_FLAG': np.int8\n",
    "    })\n",
    "\n",
    "    df.to_parquet(omni_out_dir / f'{Path(csv_file).stem}.parquet')"
   ],
   "id": "d8924c8d90cc53f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SAT_DENSITY data\n",
    "\n",
    "First of all, the SAT_DENSITY data is copied from `./data/raw/SAT_DENSITY/*.csv` to `./data/preprocessed/SAT_DENSITY/*.parquet`."
   ],
   "id": "928f89844b234912"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sd_raw_data_dir = Path(data_dir / 'raw/SAT_DENSITY/')\n",
    "sd_out_dir = Path(data_dir / 'preprocessed/SAT_DENSITY/')\n",
    "# goes_aggregated_file = Path(data_dir / 'preprocessed/aggregated/sat_density.feather')"
   ],
   "id": "1e28a0b9fd24aa8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### First tests\n",
    "\n",
    "Before creating the more compact data sets used during training, a first analysis takes place. This allows for the choosing the correct data types for all columns. In this instance the precision from `float64` is probably not needed, hence all data is converted down to `float32`. This massively reduces the necessary memory for this data."
   ],
   "id": "37356aedff36adf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print details about exemplary goes csv file\n",
    "file = next(iter(os.listdir(sd_raw_data_dir)))\n",
    "df = pd.read_csv(\n",
    "    sd_raw_data_dir / file,\n",
    "    sep=',',\n",
    "    index_col='Timestamp',\n",
    "    parse_dates=True,\n",
    ")\n",
    "print(df.info())\n",
    "df.describe()"
   ],
   "id": "b6ef80ff9621aa13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert to correct formats\n",
    "df[df['Orbit Mean Density (kg/m^3)'] > 1e+2] = -1.0\n",
    "df['Orbit Mean Density (kg/m^3)'] *= 1e3\n",
    "df = df.astype(np.float32)\n",
    "print(df.info())\n",
    "df.describe()"
   ],
   "id": "fb6be5dca2682a7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conversion\n",
    "\n",
    "After finding out, how the data must be transformed, the transformations can be applied to all csv files."
   ],
   "id": "e3a9fe51ee70d8a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for all single files\n",
    "for csv_file in tqdm(os.listdir(sd_raw_data_dir)):\n",
    "    df = pd.read_csv(\n",
    "        sd_raw_data_dir / csv_file,\n",
    "        sep=',',\n",
    "        index_col='Timestamp',\n",
    "        parse_dates=True,\n",
    "    )\n",
    "    df[df['Orbit Mean Density (kg/m^3)'] > 1e+2] = -1.0\n",
    "    df = df.astype(np.float64)\n",
    "    df.to_parquet(sd_out_dir / f'{Path(csv_file).stem}.parquet')"
   ],
   "id": "8d6b167ebccf130b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initial states data\n",
    "\n",
    "First of all, the initial states data is copied from `./data/raw/*.csv` to `./data/preprocessed/*.parquet`."
   ],
   "id": "889cdb41199a432b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "is_raw_data_dir = Path(data_dir / 'raw/')\n",
    "is_out_dir = Path(data_dir / 'preprocessed/')\n",
    "# goes_aggregated_file = Path(data_dir / 'preprocessed/aggregated/sat_density.feather')"
   ],
   "id": "e93a295544e4b615",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# helper functions with additional features\n",
    "def _scale_km(_df, _key):\n",
    "    scale_km(_df, _key)\n",
    "    _df.rename(columns={_key: _key.replace('(km)', '(1000 km)')}, inplace=True)\n",
    "\n",
    "def _convert_to_rad(_df, _key):\n",
    "    convert_to_rad(_df, _key)\n",
    "    _df.rename(columns={_key: _key.replace('(deg)', '(rad)')}, inplace=True)"
   ],
   "id": "5b5aafa24819191",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### First tests\n",
    "\n",
    "Before creating the more compact data sets used during training, a first analysis takes place. This allows for the choosing the correct data types for all columns. In this instance the precision from `float64` is probably not needed, hence all data is converted down to `float32`. This massively reduces the necessary memory for this data."
   ],
   "id": "7d5e65c012103e41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print details about exemplary goes csv file\n",
    "file = next(filter(lambda x: x.endswith('.csv'), os.listdir(is_raw_data_dir)))\n",
    "df = pd.read_csv(\n",
    "    is_raw_data_dir / file,\n",
    "    sep=',',\n",
    ")\n",
    "print(df.info())\n",
    "df.describe()"
   ],
   "id": "fa739eeb52a99a8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for better precision\n",
    "for key in [\n",
    "    'Inclination (deg)', 'RAAN (deg)', 'Argument of Perigee (deg)', 'True Anomaly (deg)', 'Latitude (deg)', 'Longitude (deg)'\n",
    "]:\n",
    "    convert_to_rad(df, key)\n",
    "\n",
    "_scale_km(df, 'Altitude (km)')\n",
    "_scale_km(df, 'Semi-major Axis (km)')\n",
    "\n",
    "# Catch obvious outliers\n",
    "df.loc[df['Longitude (rad)'] > 4, 'Longitude (rad)'] = -4.0\n",
    "df.loc[df['Latitude (rad)'] > 4, 'Latitude (rad)'] = -4.0\n",
    "df.loc[df['Altitude (1000 km)'] > 1e+6, 'Altitude (1000 km)'] = -1.0\n",
    "\n",
    "# change dtypes\n",
    "df = df.astype({\n",
    "    'File ID': np.int16,\n",
    "    'Semi-major Axis (1000 km)': np.float64,\n",
    "    'Eccentricity': np.float32,\n",
    "    'Inclination (rad)': np.float32,\n",
    "    'RAAN (rad)': np.float32,\n",
    "    'Argument of Perigee (rad)': np.float32,\n",
    "    'True Anomaly (rad)': np.float32,\n",
    "    'Latitude (rad)': np.float32,\n",
    "    'Longitude (rad)': np.float32,\n",
    "    'Altitude (1000 km)': np.float64,\n",
    "})\n",
    "\n",
    "print(df.info())\n",
    "df.describe()"
   ],
   "id": "da49f318c7953488",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conversion\n",
    "\n",
    "After finding out, how the data must be transformed, the transformations can be applied to all csv files."
   ],
   "id": "b85f4ac3cc0dbad6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for all single files\n",
    "for csv_file in tqdm(list(filter(lambda x: x.endswith('.csv'), os.listdir(is_raw_data_dir)))):\n",
    "    df = pd.read_csv(\n",
    "        is_raw_data_dir / csv_file,\n",
    "        sep=',',\n",
    "    )\n",
    "\n",
    "    for key in [\n",
    "        'Inclination (deg)', 'RAAN (deg)', 'Argument of Perigee (deg)', 'True Anomaly (deg)', 'Latitude (deg)', 'Longitude (deg)'\n",
    "    ]:\n",
    "        _convert_to_rad(df, key)\n",
    "\n",
    "    _scale_km(df, 'Altitude (km)')\n",
    "    _scale_km(df, 'Semi-major Axis (km)')\n",
    "\n",
    "    # Catch obvious outliers\n",
    "    df.loc[df['Longitude (rad)'] > 4, 'Longitude (rad)'] = -4.0\n",
    "    df.loc[df['Latitude (rad)'] > 4, 'Latitude (rad)'] = -4.0\n",
    "    df.loc[df['Altitude (1000 km)'] > 1e+6, 'Altitude (1000 km)'] = -1.0\n",
    "\n",
    "    # change dtypes\n",
    "    df = df.astype({\n",
    "        'File ID': np.int16,\n",
    "        'Semi-major Axis (1000 km)': np.float64,\n",
    "        'Eccentricity': np.float32,\n",
    "        'Inclination (rad)': np.float32,\n",
    "        'RAAN (rad)': np.float32,\n",
    "        'Argument of Perigee (rad)': np.float32,\n",
    "        'True Anomaly (rad)': np.float32,\n",
    "        'Latitude (rad)': np.float32,\n",
    "        'Longitude (rad)': np.float32,\n",
    "        'Altitude (1000 km)': np.float64,\n",
    "    })\n",
    "\n",
    "    # Save as parquet\n",
    "    df.to_parquet(is_out_dir / f'{Path(csv_file).stem}.parquet')"
   ],
   "id": "66f171f8670cf9fb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
